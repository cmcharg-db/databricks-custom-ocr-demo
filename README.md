# UK Merchant Bank OCR Demo - DeepSeek on Databricks

This repository contains a complete demonstration of deploying DeepSeek OCR on Databricks to process UK merchant bank lending documents and ingest them into a lakehouse architecture.

## ğŸ¯ Project Overview

**Use Case**: A mid-sized UK merchant bank receives lending documents from brokers in various formats and quality levels. This demo shows how to use DeepSeek OCR to automatically extract text and structured data from these documents, ingesting them into a Delta Lake-based lakehouse for analysis.

**Key Technologies**:
- **DeepSeek OCR**: MIT-licensed, on-premises OCR engine with 97% accuracy
- **Databricks**: Unified analytics platform with lakehouse architecture
- **Delta Lake**: Reliable data storage with ACID transactions
- **Unity Catalog**: Data governance and model registry
- **MLflow**: Model lifecycle management

## ğŸ”„ Code Reuse

Shared modules ensure identical functionality between local and Databricks:
- ~95% code reuse via shared `generators/`, `config.py`, `scan_effects.py`
- Same seed â†’ same output
- Edit once â†’ applies everywhere

[View Architecture â†’](CODE_REUSE_GUIDE.md)

## ğŸ“š Documentation

### Quick Links

| Document | Description |
|----------|-------------|
| [**IMPLEMENTATION_PLAN.md**](IMPLEMENTATION_PLAN.md) | Complete 8-phase implementation plan |
| [**CODE_REUSE_GUIDE.md**](CODE_REUSE_GUIDE.md) | Shared code architecture |
| [**DATA_GENERATION_SUMMARY.md**](DATA_GENERATION_SUMMARY.md) | Document generation overview |
| [**data_gen/QUICKSTART.md**](data_gen/QUICKSTART.md) | Getting started guide |
| [**data_gen/README.md**](data_gen/README.md) | Document generator details |
| [**databricks_notebooks/README.md**](databricks_notebooks/README.md) | Databricks setup guide |

## ğŸš€ Quick Start

### Choose Your Approach

**Option A: Local Generation (Recommended for Development)**

Generate documents on your local machine:

```bash
cd data_gen

# Install dependencies
pip install -r requirements.txt

# Test your setup
python test_setup.py

# Generate 40 synthetic lending documents
python generate_all.py

# Add realistic scanning artifacts
python add_scan_effects.py --percentage 30
```

**Time:** ~5 minutes | **Output:** 40 pristine + 12 scanned PDFs

---

**Option B: Databricks Notebooks**

Generate documents directly in Databricks workspace:

1. Upload `data_gen/` folder to Databricks Workspace or Repos
2. Create Unity Catalog volume:
   ```sql
   CREATE VOLUME lending_documents.raw_data.synthetic_docs;
   ```
3. Import and run `databricks_notebooks/01_generate_documents_modular.py`
4. (Optional) Run `databricks_notebooks/03_add_scan_effects.py` for quality variations

**Output:** PDFs in Unity Catalog Volume, ready for OCR pipeline

ğŸ“– **[Databricks Setup Guide](databricks_notebooks/README.md)**

---

## ğŸ­ Next Steps: Deploy on Databricks

Follow the [IMPLEMENTATION_PLAN.md](IMPLEMENTATION_PLAN.md) to:

1. **Setup Environment** (Phase 1)
   - Configure Databricks workspace with GPU cluster
   - Set up Unity Catalog
   - Configure cloud storage

2. **Deploy DeepSeek OCR** (Phase 2-3)
   - Download and package model
   - Register in MLflow
   - Create serving endpoint

3. **Build Data Pipeline** (Phase 4)
   - Bronze Layer: Raw document ingestion
   - Silver Layer: OCR text extraction
   - Gold Layer: Structured data parsing

4. **Create Demo** (Phase 7)
   - End-to-end notebook
   - SQL analytics dashboard
   - Presentation materials

## ğŸ“ Project Structure

```
custom_ocr_demo/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ IMPLEMENTATION_PLAN.md             # 8-phase implementation plan
â”œâ”€â”€ CODE_REUSE_GUIDE.md                # Shared code architecture
â”œâ”€â”€ DATA_GENERATION_SUMMARY.md         # Document generation overview
â”‚
â”œâ”€â”€ databricks_notebooks/              # Databricks notebooks
â”‚   â”œâ”€â”€ README.md                      # Setup guide
â”‚   â”œâ”€â”€ 01_generate_documents_modular.py  # Document generation
â”‚   â””â”€â”€ 03_add_scan_effects.py        # Scan effects
â”‚
â””â”€â”€ data_gen/                          # Local & shared modules
    â”œâ”€â”€ README.md                      # Documentation
    â”œâ”€â”€ QUICKSTART.md                  # Getting started
    â”œâ”€â”€ requirements.txt               # Dependencies
    â”œâ”€â”€ config.py                      # â† Shared configuration
    â”œâ”€â”€ scan_effects.py                # â† Shared scan effects
    â”œâ”€â”€ test_setup.py                  # Setup verification
    â”œâ”€â”€ generate_all.py                # Local generation script
    â”œâ”€â”€ add_scan_effects.py            # Local scan script
    â”‚
    â”œâ”€â”€ generators/                    # â† Shared generators
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ document_utils.py
    â”‚   â”œâ”€â”€ loan_agreements.py
    â”‚   â”œâ”€â”€ term_sheets.py
    â”‚   â””â”€â”€ financial_statements.py
    â”‚
    â””â”€â”€ outputs/                       # Generated PDFs (gitignored)
        â”œâ”€â”€ loan_agreements/
        â”œâ”€â”€ term_sheets/
        â”œâ”€â”€ financial_statements/
        â”œâ”€â”€ scanned/
        â””â”€â”€ manifest.txt
```

## ğŸ“„ Document Types

### Loan Facility Agreements (5-8 pages)
Full UK-style facility agreements with proper legal structure:
- Parties and definitions
- Facility terms and conditions
- Financial covenants
- Security package details
- Repayment schedules
- Signature blocks

**Sample loan amounts**: Â£500K - Â£50M

### Broker Term Sheets (2-3 pages)
Concise deal summaries that brokers send to lenders:
- Transaction overview
- Key commercial terms
- Borrower profile and financials
- Security package
- Broker recommendations

### Financial Statements (3-4 pages)
Complete UK company accounts:
- Profit & Loss statement
- Balance Sheet
- Notes to accounts
- Key financial ratios
- Director signatures

## ğŸ¨ Quality Levels

Documents are generated at three quality levels to test OCR robustness:

| Quality | Description | Usage |
|---------|-------------|-------|
| **Pristine** | Clean, native PDFs | 70% of documents |
| **Light Scan** | Minimal artifacts | 20% of documents |
| **Heavy Scan** | Significant degradation | 10% of documents |

## ğŸ—ï¸ Architecture

```mermaid
flowchart TB
    Broker[Broker Document Submission] --> Storage[Cloud Storage Landing Zone]
    Storage --> Autoloader[Databricks Autoloader]
    Autoloader --> Bronze[(Bronze Layer<br/>Raw Documents)]
    Bronze --> OCRPipeline[DeepSeek OCR Processing]
    OCRPipeline --> MLServing[Model Serving Endpoint]
    MLServing --> Silver[(Silver Layer<br/>Extracted Text + Metadata)]
    Silver --> Parsing[Field Extraction & Validation]
    Parsing --> Gold[(Gold Layer<br/>Structured Lending Data)]
    Gold --> Analytics[SQL Analytics & Dashboards]
    
    DeepSeekModel[DeepSeek OCR Model<br/>MIT License] --> MLflow[MLflow Model Registry]
    MLflow --> Unity[Unity Catalog]
    Unity --> MLServing
```

## â±ï¸ Timeline

| Phase | Description | Duration |
|-------|-------------|----------|
| **Phase 0** | Generate test documents | 5 minutes |
| **Phase 1-2** | Environment & Model Setup | 2-3 days |
| **Phase 3** | Model Deployment | 1-2 days |
| **Phase 4** | Data Pipeline (Bronzeâ†’Silverâ†’Gold) | 3-4 days |
| **Phase 5** | Sample Data & Testing | 2-3 days |
| **Phase 6** | Orchestration & Monitoring | 2-3 days |
| **Phase 7** | Demo Materials | 2-3 days |
| **Phase 8** | Documentation | 1-2 days |
| **TOTAL** | | **11-17 days** |

## âœ… Success Metrics

- **Accuracy**: >95% field extraction accuracy on validation set
- **Throughput**: Process 100+ documents per hour
- **Latency**: <10 seconds per document (single page)
- **Data Quality**: >90% confidence score on extracted text
- **Business Value**: 80% time reduction vs. manual data entry

## ğŸ”’ Compliance & Security

**Important for UK Financial Services:**

- âœ… **On-premises deployment**: DeepSeek OCR runs locally (MIT license)
- âœ… **Data residency**: All data stays within your Databricks workspace
- âœ… **FCA compliant**: No third-party API calls or data sharing
- âœ… **Audit trail**: Complete lineage via Unity Catalog
- âœ… **Governance**: Role-based access control

## ğŸ› ï¸ Prerequisites

### For Document Generation
- Python 3.8+
- pip package manager

### For Databricks Deployment
- Databricks workspace with Unity Catalog
- GPU-enabled cluster (A100 or V100 recommended)
- Cloud storage (AWS S3 / Azure ADLS / GCP GCS)
- MLflow Model Registry access

## ğŸ“Š Demo Flow

1. **Show raw documents**: Mixed quality PDFs from brokers
2. **Demonstrate ingestion**: Autoloader picks up new files
3. **OCR processing**: DeepSeek extracts text with high accuracy
4. **Structured output**: Show Silver layer with extracted text
5. **Parsed data**: Display Gold layer with structured fields
6. **Analytics**: Run SQL queries on lending data
7. **Dashboard**: Visualize key metrics and trends

## ğŸ’¡ Key Features

### Realistic Synthetic Data
- UK-specific company names, addresses, legal terminology
- Varied document formats and layouts
- Proper accounting (balance sheets balance!)
- Realistic financial ratios and covenants

### Production-Ready Code
- Extensive documentation and comments
- Error handling and logging
- Configurable parameters
- Reproducible with seeds

### Comprehensive Pipeline
- Bronzeâ†’Silverâ†’Gold medallion architecture
- Data quality checks and validation
- Monitoring and alerting
- SQL analytics ready

## ğŸ¤ Contributing

This is a demo project. To customize:

1. **Modify document parameters**: Edit `data_gen/config.py`
2. **Add document types**: Create new generators in `data_gen/generators/`
3. **Adjust OCR logic**: Modify pipeline notebooks (created in Phase 4)
4. **Extend analytics**: Add queries and dashboards (Phase 7)

## ğŸ“– Additional Resources

- [DeepSeek OCR Documentation](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html)
- [Databricks Lakehouse Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)
- [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html)

## ğŸ“ Learning Path

1. **Start here**: Generate documents (`data_gen/QUICKSTART.md`)
2. **Understand the plan**: Read `IMPLEMENTATION_PLAN.md`
3. **Setup Databricks**: Follow Phase 1 of implementation plan
4. **Deploy model**: Follow Phases 2-3
5. **Build pipeline**: Follow Phase 4
6. **Create demo**: Follow Phase 7

## ğŸ“ Support

For issues with:
- **Document generation**: Check `data_gen/README.md` and comments in code
- **Databricks setup**: Refer to `IMPLEMENTATION_PLAN.md` Phase 1
- **OCR deployment**: See `IMPLEMENTATION_PLAN.md` Phases 2-3
- **Pipeline development**: Review `IMPLEMENTATION_PLAN.md` Phase 4

## ğŸ“ License

This demo project uses:
- **DeepSeek OCR**: MIT License (on-premises deployment)
- **Databricks**: Requires commercial license
- **Generated code**: Free to use and modify for your demos

---

**Ready to start?** Run `cd data_gen && python test_setup.py` to begin! ğŸš€
